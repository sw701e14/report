\section{Modelling Behaviour}
As the purpose of \projectname{} is to be able to predict the movement of bikes at a given time (see \mikkel{Insert reference to problem statement}), it must be able to answer questions such as the following:
\begin{itemize}
\item How much time will it take before a bike, with probability 90\%, will be in my vicinity?
\item What is the probability of finding a bike nearby from 16.25 to 16.35?
\end{itemize}

The location of the bikes are abstracted by creating hotspots, as described in \cref{hotspots}.
In actuality, the location of bikes is modeled to be more complex as will be further explored in \cref{markov:modeling}.
However the theory and methods described in the following sections apply regardless.

By abstracting the locations to be hotspots the above questions can be rephrased as:

\begin{itemize}
\item How much time will it take before a bike, with probability 90\%, will be \textit{in a given hotspot}?
\item What is the probability of finding a bike \textit{in a given hotspot} from 16.25 to 16.35?
\end{itemize}

To answer these questions we need to model the behavior of an \textit{average} bike.
In other words, we need to provide a formal description of the movement of a single bike representing the movement, on average, of all bikes.

\subsection{Abstraction Model}
As the system is based on anonymous usage no user sensitive information is collected.
Because of this uncertainty in the modeling is expected, as all bikes (and thus all users) are modeled as a single \textit{average bike}.
Modeling the movement of all bikes will be done by modeling the movement of this average bike.

Asides from that we must also consider that our model will be working on discrete-time location data.
The GPS units that the bikes will be equipped with will only report the location of a bike at a \textit{fixed} interval.
Additionally the accuracy of each of these measurements can be low, resulting in even more in-precision.

As we are modeling the average bike, we can represent the state of the process as the location of the bike.
The location of the bike can be seen as which hotspot the bike is currently located at.
Using this definition we can describe the movement of the bike as an infinite route $h_1, h_2, h_3, \dots$ where $h_i \in H \mid i \in \mathbb{N}$ and $H$ is the set of hotspots in the system.

Using this representation of the average bike we see that the average bike must move from one hotspot $h_i$ to another $h_{i+1}$ in one \textit{timestep}.
Note that it could be that $h_i = h_{i+1}$, meaning that the bike has moved to the same hotspot as it departed from.
This is also used to indicate that the bike has not moved.
In \cref{markov:modeling} we will describe the modeling of the average city bike in greater detail.

Taking all of the above into account, it is reasonable to suggest the abstraction model, for the behavior of the average city bike, being a discrete-time Markov chain, where the states are used to represent hotspots.

\subsection{Discrete-Time Markov Chains}\label{markov}
A discrete-time Markov chain models state changes in a process at discrete time intervals.
It can be viewed as a sequence (chain) of random variables $X_1, X_2, X_3, \dots$ where each such variable is a function $X_i:S \rightarrow x$.
Here $S$ is a countable set of states representing the possible states (hotspots) in the process described by the Markov chain and $x$ is a \textit{random} state from $S$.
The subscript describes the time associated with each of the variables.
Thus $X_i$ represents the possible states of the process at time $i$.
This notation allows us to establish a timespan as each step refers to a fixed interval.

This randomness will be biased towards certain states given its current state (and possibly time) resulting in a set of probabilities for each state given a random variable.
Let $\mathbb{P}(X_i = x)$ be the probability of $X_i$ being in state $x$.
The above will then allow us to express the probability of moving to a state $y$ given the path we have traversed.
In other words, knowing what state we are in and how we got to it allows us to determine the probability of the next state being $y$:

$$\mathbb{P}(X_{n+1} = y \mid X_1 = x_1, X_2 = x_2, \dots X_n = x)$$

\paragraph{Markov property}\label{markov:property}
For the sequence to describe a Markov chain it must additionally have the Markov property.
The Markov property states that for any state $x$ we can determine the probability of the next state being $y$ without any knowledge of the path that led to $x$.
We can formalize this as:

\begin{align}\label{markov:eq:markov_prob}
\mathbb{P}(&X_{n+1} = y \mid X_1 = x_1, X_2 = x_2, \dots X_n = x)\nonumber\\
= \mathbb{P}(&X_{n+1} = y \mid X_n = x)
\end{align}

\paragraph{Time-homogeneous Markov chains}
In an effort to simplify the problem of predicting the behavior of the average bike we will be using time-homogeneous Markov chains.
A Time-homogeneous Markov chain can also be thought of as a time-independent chain.
In other words, predicting the next state of the chain can be done without knowledge of the time:
\begin{equation}
\mathbb{P}(X_{m+1} = y \mid X_m = x) = \mathbb{P}(X_{n+1} = y \mid X_n = x)
\end{equation}

Time-homogeneous Markov chains provides us with a much simpler method of modeling the average bike.
A time-homogeneous Markov chain is very simple to represent (as is described below) and easy to use when predicting the state of the average bike multiple steps into the future.
For these reasons we have chosen to simplify our Markov chain models.

\textit{This simplification will mean that we are unable to determine a difference in behavior at different times in the process.
Thus we cannot, using a single model, represent different behaviors of the average bike in the morning/afternoon or in different days of the week.
To allow for this distinction multiple models could be generated, representing different datasets.
The system would then simply select the model that corresponds to the current time-of-day/day-of-week.}

\paragraph{Mathematical representation}
From the above definitions we have that a Markov chain $\mathcal{M}$ can be described as a function $\tau_M:S\times S \rightarrow [0;1]$ such that $\tau_M(x, y) = \mathbb{P}(X_{n + 1} = y \mid X_n = x)$.
As the chain is independent of time we can represent it using a single matrix containing all its transitional probabilities.
This is a simple representation that allows us to predict multiple steps into the future by applying the same matrix to some initial state multiple times.

\paragraph{Visual representation}
Markov chains are typically represented using a DAG\footnote{Directed Acyclic Graph} with weight on its edges.
In such a graph nodes represent states and the weight of edges represent the probability of transitioning between two states.
This is a direct mapping of the matrix described above.

In \cref{markov:model:simple} we give an example of a Markov chain that models an average city bike traveling back and forth between two hotspots $\{H_1, H_2\}$.
From the weights on the diagram edges we can read the time-homogeneous probability of moving from one state to another (or staying in the same state).
For instance, a Markov chain currently in $H_1$ has probability $0.7$ of transitioning to $H_1$ (staying) and probability $0.3$ of transitioning to $H_2$.

In the diagram there are no edges with weight zero.
Any such edges would represent transitions with zero probability (\textit{``impossible``} transitions).
Had there been edges with weight zero, they could have been removed to simplify it.
This also means that any \textit{missing} edge between two states $s_1$ and $s_2$ implies that $\tau(s_1, s_2) = 0$.
Examples of this can be seen in \cref{markov:model:complex} where states $D_1$ and $D_2$ are not connected.

\subsection{Modeling the average bike}\label{markov:modeling}
Throughout this section we have described the modeling of the average bike as an infinite path of hotspots.
We represent a simple example of this, using only two hotspots, in \cref{markov:model:simple}.
\input{content/markov_model_simple}
Using this system we will be able to predict the path of the bike in the system.
To do this we require an initial state for the system.
This state should represent the current (the time of a query) location of the bikes in the system.
Using this representation we will be able to predict where the bikes are after a number of time steps.

\paragraph{Insufficient states}
As we are looking to use the Markov chains to predict whether or not a bike is available at a hotspot we must also be able to represent whether they are in use or not.
The modeling described so far only allows for a bike to be at a hotspot and thus we are not able to give a direct representation of a bike in transit.

To accommodate this restriction we introduce an additional state for each of the hotspots.
These states are called departure states and the departure state associated with hotspot $H_i$ is denoted as $D_i$.
The simple two-hotspots model described above can then be expanded with two additional states, as seen in \cref{markov:model:complex}.

\input{content/markov_model_complex}

These states allow us to represent bikes that are not currently located at a hotspot.
Note that in this model some transitions are not possible.
These are $D_i \rightarrow D_j \mid i \neq j$ and $H_i \rightarrow D_j \mid i \neq j$ transitions.
They are not possible, simply because as a bike must travel through $H_j$ before it can arrive at its departure state $D_j$.

This model allows us to initialize a Markov chain using some initial state representing the current (the time of a query) location of the bikes and then predict where the bikes will be located after a number of time steps.
From this prediction it is then possible to read exactly how many bikes should be available at a given hotspot in a given timespan.
