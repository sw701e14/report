\section{Modeling Behavior}\label{modelbehavior}
As the purpose of \projectname{} is to be able to predict the movement of bikes at a given time (see \Cref{problem_statement}), it must be able to answer questions such as: 

\begin{itemize}
\item How much time will it take before a bike will be in my vicinity?
\end{itemize}

The location of the bikes are abstracted by creating hotspots, as described in \Cref{hotspots}.
In actuality, the location of bikes is modeled to be more complex as will be further explored in \Cref{markov:modeling}.
However the theory and methods described in the following sections apply regardless.

By abstracting the locations to be hotspots the above question can be rephrased as: 

\begin{itemize}
\item How much time will it take before a bike will be \emph{in a given hotspot}?
\end{itemize}


To answer this question we need to model the behavior of an \emph{average} bike.
In other words, we need to provide a formal description of the movement of a single bike representing the movement, on average, of all bikes.

\subsection{Abstraction Model}
As the system is based on anonymous usage no user sensitive information is collected.
Because of this some uncertainty is expected in the model, as all bikes (and thus all users) are modeled as a single \textit{average bike}.
Modeling the movement of all bikes will be done by modeling the movement of this average bike as a stochastic process \cite{stochastic}.

We must also consider that our model will be working on discrete-time location data.
The GPS units that the bikes will be equipped with will only report the location of a bike at a \textit{fixed} interval.
Additionally the accuracy of each of these measurements can be low, resulting in even more imprecision.
As we are modeling the average bike, we can represent the state of the process as the location of the bike.
In order to reduce the number of locations to a sensible number we will use the generated hotspots instead.
Using this definition we can describe the movement of the bike as an infinite route $h_1, h_2, h_3, \dots$ where $h_i \in H \mid i \in \mathbb{N}$ and $H$ is the set of hotspots in the system.

Using this representation of the average bike we see that the average bike must move from one hotspot $h_i$ to another $h_{i+1}$ in one \emph{timestep}.
Note that it could be that $h_i = h_{i+1}$, meaning that the bike has moved to the same hotspot as it departed from.
This is also used to indicate that the bike has not moved.
In \Cref{markov:modeling} we will describe the modeling of the average city bike in greater detail.

Taking all of the above into account it is reasonable to suggest the abstraction model for the behavior of the average city bike, to be a discrete-time Markov chain where the states are used to represent hotspots.

\subsection{Discrete-Time Markov Chains}\label{markov}
The state of a discrete-time Markov chain model changes in a process at discrete time intervals.
It can be viewed as a sequence (chain) of random variables $X_1, X_2, X_3, \dots$ where each such variable is a function $X_i:S \rightarrow x$.
Here $S$ is a countable set of states representing the possible states (hotspots) in the process described by the Markov chain and $x$ is a \textit{random} state from $S$.
The subscript describes the time associated with each of the variables.
Thus $X_i$ represents the possible states of the process at time $i$.
This notation allows us to establish a timespan as each step refers to a fixed interval.

This randomness will be biased towards certain states given its current state (and possibly time) resulting in a set of probabilities for each state given a random variable.
Let $\mathbb{P}(X_i = x)$ be the probability of $X_i$ being in state $x$.
The above will then allow us to express the probability of moving to a state $y$ given the path we have traversed.
In other words, knowing what state we are in and how we got to it allows us to determine the probability of the next state being $y$:

$$\mathbb{P}(X_{n+1} = y \mid X_1 = x_1, X_2 = x_2, \dots X_n = x)$$

\paragraph{Markov property}\label{markov:property}
For the sequence to describe a Markov chain it must additionally have the Markov property.
The Markov property states that for any state $x$ we can determine the probability of the next state being $y$ without any knowledge of the path that led to $x$.
We can formalize this as:

\begin{align}\label{markov:eq:markov_prob}
\mathbb{P}(&X_{n+1} = y \mid X_1 = x_1, X_2 = x_2, \dots X_n = x)\nonumber\\
= \mathbb{P}(&X_{n+1} = y \mid X_n = x)
\end{align}

\paragraph{Time-homogeneous Markov chains}
In an effort to simplify the problem of predicting the behavior of the average bike we will be using time-homogeneous Markov chains.
A Time-homogeneous Markov chain can also be thought of as a time-independent chain.
In other words, predicting the next state of the chain can be done without knowledge of the time:
\begin{equation}
\mathbb{P}(X_{m+1} = y \mid X_m = x) = \mathbb{P}(X_{n+1} = y \mid X_n = x)
\end{equation}

Time-homogeneous Markov chains provides us with a much simpler method of modeling the average bike.
A time-homogeneous Markov chain is very simple to represent (as is described below) and easy to use when predicting the state of the average bike multiple steps into the future.
For these reasons we have chosen to simplify our Markov chain models.

This simplification will mean that we are unable to determine a difference in behavior at different times in the process.
Thus we cannot, using a single model, represent different behaviors of the average bike in the morning/afternoon or in different days of the week.
To allow for this distinction multiple models could be generated, representing different datasets.
The system would then simply select the model that corresponds to the current time-of-day/day-of-week.

\paragraph{Mathematical representation}\label{markov:math}
From the above definitions we have that a Markov chain $\mathcal{M}$ can be described as a function $\tau_M:S\times S \rightarrow [0;1]$ such that $\tau_M(x, y) = \mathbb{P}(X_{n + 1} = y \mid X_n = x)$.
As the chain is independent of time we can represent it using a single matrix containing all its transitional probabilities.
Below is a generic representation of such a matrix:

\begin{equation}\label{markov:matrix}
\begin{bmatrix}
\tau_M(s_0, s_0) & \tau_M(s_0, s_1) & \cdots & \tau_M(s_0, s_n)\\
\tau_M(s_1, s_0) & \tau_M(s_1, s_1) & \cdots & \tau_M(s_1, s_n)\\
\vdots & \vdots & \ddots & \vdots\\
\tau_M(s_n, s_0) & \tau_M(s_n, s_1) & \cdots & \tau_M(s_n, s_n)
\end{bmatrix}
\end{equation}

This is a simple representation that allows us to predict probabilities multiple steps into the future by applying the same matrix to some initial probability distribution multiple times.

\paragraph{Visual representation}
Markov chains are typically represented using a DAG\footnote{Directed Acyclic Graph} with weight on its edges.
In such a graph nodes represent states and the weight of edges represent the probability of transitioning between two states.
This is a direct mapping of the matrix described above.

In \Cref{markov:model:simple} we give an example of a Markov chain that models an average city bike traveling back and forth between two hotspots $\{H_1, H_2\}$.
From the weights on the diagram edges we can read the time-homogeneous probability of moving from one state to another (or staying in the same state).
For instance, a Markov chain currently in $H_1$ has probability $0.7$ of transitioning to $H_1$ (staying) and probability $0.3$ of transitioning to $H_2$.

In the diagram there are no edges with weight zero.
Any such edges would represent transitions with zero probability (\textit{``impossible``} transitions).
Had there been edges with weight zero, they could have been removed to simplify the graph.
This also means that any \textit{missing} edge between two states $s_1$ and $s_2$ implies that $\tau(s_1, s_2) = 0$.
Examples of this can be seen in \Cref{markov:model:complex} where states $D_1$ and $D_2$ are not connected.

\subsection{Modeling the average bike}\label{markov:modeling}
\texttt{New}\\
Throughout this section we have described the modeling of the average bike as a distribution on a set of infinite paths of hotspots.\\
\texttt{Old}\\
Throughout this section we have described the modeling of the average bike as an infinite path of hotspots.
\mikael{Giovanni stadig ikke tilfreds med den her.}
\bruno{Hvad er han ikke tilfreds med?}
\alexander{Something about the average bike being modeled as an `infinite path of hotspots'.}
\alexander{I have given it a shot, read it and tell me what you think.}
We represent a simple example of this, using only two hotspots, in \Cref{markov:model:simple}.
\input{content/markov_model_simple}
Using this system we will be able to make predictions on the path of the bike in the system.
To do this we require an initial state for the system.
This state should represent the current (at the time of a query) location of the bikes in the system.
Using this representation we will be able to compute the probability that the bikes will be in some hotspot after a number of time steps.

\paragraph{Insufficient states}
As we are looking to use the Markov chains to predict whether or not a bike is available at a hotspot we must also be able to represent whether they are in use or not.
The modeling described so far only allows for a bike to be at a hotspot and thus we are not able to give a direct representation of a bike in transit.

To accommodate this restriction we introduce an additional state for each of the hotspots.
These states are called \emph{departure states} and the departure state associated with hotspot $H_i$ is denoted as $D_i$.
The simple two-hotspots model described above can then be expanded with departure states, as seen in \Cref{markov:model:complex}.

\input{content/markov_model_complex}

These states allow us to represent bikes that are not currently located at a hotspot.
Note that in this model some transitions are not possible.
These are $D_i \rightarrow D_j$ and $H_i \rightarrow D_j $ for $i \neq j$ transitions.
This models the fact that a bike must transit through $H_j$ before it can arrive at its departure state $D_j$.

This model allows us to initialize a Markov chain using some initial state representing the current (the time of a query) location of the bikes and then predict where the bikes will be located after a number of time steps.
From this prediction it is then possible to predict how many bikes should be available at a given hotspot in a given timespan according to our model.

\paragraph{Ordered matrix}
To ensure that the various parts of this section, as well as the implementation, works consistently we introduce a set ordering of states in the matrix.
In this representation of the matrix $(x, y)$ is used to denote $\tau_M(x, y)$.
This is done solely to simplify the matrix.

\begin{equation}\label{markov:matrix-ordered}
\begin{bmatrix}
(h_0, h_0) & (h_0, d_0) &
(h_0, h_1) & (h_0, d_1) &
\cdots &
(h_0, h_n) & (h_0, d_n)\\

(d_0, h_0) & (d_0, d_0) &
(d_0, h_1) & (d_0, d_1) &
\cdots &
(d_0, h_n) & (d_0, d_n)\\


(h_1, h_0) & (h_1, d_0) &
(h_1, h_1) & (h_1, d_1) &
\cdots &
(h_1, h_n) & (h_1, d_n)\\

(d_1, h_0) & (d_1, d_0) &
(d_1, h_1) & (d_1, d_1) &
\cdots &
(d_1, h_n) & (d_1, d_n)\\


\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\


(h_n, h_0) & (h_n, d_0) &
(h_n, h_1) & (h_n, d_1) &
\cdots &
(h_n, h_n) & (h_n, d_n)\\

(d_n, h_0) & (d_n, d_0) &
(d_n, h_1) & (d_n, d_1) &
\cdots &
(d_n, h_n) & (d_n, d_n)
\end{bmatrix}
\end{equation}
