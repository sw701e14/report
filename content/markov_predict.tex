\section{Making predictions}
As a Markov chain $\mathcal{M}$ can be represented with a matrix $\mathbf{M}$ (constructed from \Cref{markov:create_model}), we can use $\mathbf{M}$ to give an estimate of the behavior of the average bike in future time-steps.
For this we require an initial probability distribution for the average bike.
We can then apply $\mathbf{M}$ to this distribution to determine the probability of the average bike being in various states after a number to time-steps.
In this section, we will describe how this initial state is established and how we use it to handle predictions.

It should be noted, that the use of the term \textit{''prediction''} in this section refers to determining possible future states of a system, estimated by the Markov chain model.

\paragraph{Notation}
We will introduce some notation in order to describe the various probability distributions of Markov chains.
Let
\begin{itemize}
\item $X_0$ be the random variable representing the possible initial states.
\item $H = \{h_0, h_1, \dots, h_n\}$ be the set of hotspots.
\item $D = \{d_0, d_1, \dots, d_n\}$ be the set of departure states.
\item $S = H \cup D$ be the set of all states.
\item $P_j(h_i) = \mathbb{P}(X_j = h_i)$ and $P_j(d_i) = \mathbb{P}(X_j = d_i)$
\end{itemize}

Additionally we let $P_j$ represent a vector with the probability distribution of the random variable $X_j$.
To formalize this definition, we use the following:

\begin{equation}\label{markov:vector}
P_j = \Big(
P_j(h_0),\;
P_j(d_0),\;
P_j(h_1),\;
P_j(d_1),\;
\dots,\;
P_j(h_n),\;
P_j(d_n)
\Big)
\end{equation}

\subsection{Initial distribution}
The initial probability distribution represents the probability of the \textit{average} bike being in each of the states (hotspots or departure states) in the system.
Thus we can simply examine all the bikes in the system and identify their current location.

The current location of a bike $L(b)$ can be either a hotspot or a departure state; $L(b) \in S$.
The probability of the average bike being in state $s$ will then be equal to the fraction of bikes that are actually in $s$.

Let $B$ be the set of all active bikes in the system and $B_j(s) \in B$ be the set of bikes in state $s$ at time $j$ as described by the model.
$B_0(s)$ will then be the initial set of bikes in state $s$ and we can represent the probability distribution as the following:
\begin{equation}\label{markov:vector:init}
P_0 = \Bigg(
\frac{\lvert B_0(h_0) \rvert}{\lvert B \rvert},\;
\frac{\lvert B_0(d_0) \rvert}{\lvert B \rvert},\;
\frac{\lvert B_0(h_1) \rvert}{\lvert B \rvert},\;
\frac{\lvert B_0(d_1) \rvert}{\lvert B \rvert},\;
\dots,\;
\frac{\lvert B_0(h_n) \rvert}{\lvert B \rvert},\;
\frac{\lvert B_0(d_n) \rvert}{\lvert B \rvert}
\Bigg)
\end{equation}

\paragraph{Location of a bike}
Looking at the coordinates of a single bike we are able to determine if it is inside a hotspot or not.
If it is not, we will iterate backwards through the set of known locations of a bike until we find it located in a hotspot $h_i$.
We then say that the bike is currently in state $d_i$.
If there is no data placing a bike within a hotspot the bike will instead be said to be in the departure state of the nearest hotspot.
In this context nearest refers to the hotspot that has the lowest minimum distance to the last known location of the bike.

\paragraph{An example}
With a set of states such as the one in \cref{markov:model:complex} and a total of 16 bikes we could have a distribution of bikes as follows:
8 bikes are currently located in hotspot $H_1$, while 2 bikes have left it, but have not arrived in another hotspot.
They are in departure state $D_1$.
Finally 6 bikes are located in hotspot $H_2$ and none are in its departure state.

Such a distribution of bikes would result in an initial probability distribution of the average bike as below:
$$P_0 = \left(\frac{8}{16}, \frac{2}{16}, \frac{6}{16}, \frac{0}{16}\right)=(0.5, 0.125, 0.375, 0)$$\label{markov:example-vector}
This distribution will be used to determine future probability distributions of the system.
In the following section this example will be revisited, providing such informations.

\subsection{Predicting from the initial distribution}
Having represented the probability distributions as vectors we can multiply them with the transitional matrices described in \cref{markov} and \cref{sec:generatemarkov}.
Such a multiplication would result in a vector with the probability distribution of the individual states after one time-step.
In other words:
\begin{equation}
P_{t+1} = M  P_t
\end{equation}
Using this definition we can define $P_1$ from $P_0$.
To do this we look at a single value in the vector $P_1$; $P_1(h_0)$.
The remaining values in the vector are defined in a similar manor.

Using the probability matrix from \Cref{markov:matrix-ordered} on page \pageref{markov:matrix-ordered} we can determine $P_1(h_0)$.
Additionally we can use \Cref{markov:vector:init} to further specify the value:
$$
P_1(h_0) = 
\frac{\lvert B_0(h_0) \rvert}{\lvert B \rvert}
\cdot \tau_M(h_0, h_0) + \dots +
\frac{\lvert B_0(d_n) \rvert}{\lvert B \rvert}
\cdot \tau_M(d_n, h_0)
$$
This will then represent the probability that the average bike is in state $h_0$ after one time-step.
As this models a single average bike we can multiply the probability with the number of bikes in order to determine the expected number of bikes in $h_0$ at time 1:

$$B_1(h_0) = P_1(h_0) \cdot |B|$$

This definition of $B_1(h_0)$ can be simplified by removing the $|B|$ from each term.
This gives a simple definition of the value, that can be easily shown to be true for all $B_1(s) \mid s \in S$.
Thus we can use this process to retrieve $B_1$ as a vector.
Using a similar argument we can also show that the same rule applies to all $B_j$.

$$
B_1(h_0) = 
\lvert B_0(h_0) \rvert
\cdot \tau_M(h_0, h_0) + \dots +
\lvert B_0(d_n) \rvert
\cdot \tau_M(d_n, h_0)
$$

Because of this predictions can be handled by working directly from the initial distribution of bikes, instead of the distribution of probabilities.
We can then directly calculate the expected distribution of bikes in future steps of the Markov chain.

\paragraph{An example}
Given the distribution of bikes from page \pageref{markov:example-vector} and the transition probabilities given in \Cref{markov:model:complex} on page \pageref{markov:model:complex} we can estimate the location of the 16 bikes in the example system.
The initial distribution of bikes $(8, 2, 6, 0)$, which multiplied by the matrix yield the following results:
$$
(8, 2, 6, 0)
\begin{bmatrix}
0.65 & 0.3 & 0.05 & 0\\
0.1  & 0.6 & 0.3  & 0\\
0.15 & 0   & 0.35 & 0.5\\
0.2  & 0   & 0.1  & 0.7
\end{bmatrix}
=
(6.3, 3.6, 3.1, 3)
$$
